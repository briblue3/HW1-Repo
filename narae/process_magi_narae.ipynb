{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing The Gift of the Magi by O. Henry\n",
    "\n",
    "By Na-Rae the Student\n",
    "\n",
    "Yep, not a real corpus, but just as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start by importing NLTK\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gift of the Magi\n",
      "by O. Henry\n",
      "\n",
      "One dollar and eighty-seven cents. That was all. And sixty cents of it was in pennies. Pennies saved one and two at a time by bulldozing the grocer and the vegetable man and the butcher until one's cheeks burned with the silent imputation of parsimony that such close dealing implied. Three times Della counted it. One dollar and eighty-seven cents. And the next day would be Christmas.\n",
      "\n",
      "There was clearly nothing left to do but flop down on the shabby little couch \n"
     ]
    }
   ],
   "source": [
    "# read in the text, print first 500 characters\n",
    "magitxt = open('data/gift_of_magi.txt').read()\n",
    "print(magitxt[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Gift', 'of', 'the', 'Magi', 'by', 'O.', 'Henry', 'One', 'dollar', 'and', 'eighty-seven', 'cents', '.', 'That', 'was', 'all', '.', 'And', 'sixty', 'cents', 'of', 'it', 'was', 'in', 'pennies', '.', 'Pennies', 'saved', 'one', 'and', 'two', 'at', 'a', 'time', 'by', 'bulldozing', 'the', 'grocer', 'and', 'the', 'vegetable', 'man', 'and', 'the', 'butcher', 'until', 'one', \"'s\", 'cheeks']\n"
     ]
    }
   ],
   "source": [
    "# tokenize text into a list of word tokens, print out first 50\n",
    "magitoks = nltk.word_tokenize(magitxt)\n",
    "print(magitoks[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 141),\n",
       " ('the', 109),\n",
       " (',', 104),\n",
       " ('and', 75),\n",
       " ('a', 65),\n",
       " ('of', 51),\n",
       " ('to', 41),\n",
       " ('``', 30),\n",
       " (\"''\", 30),\n",
       " ('it', 29),\n",
       " ('was', 27),\n",
       " ('Jim', 26),\n",
       " ('she', 25),\n",
       " ('in', 24),\n",
       " ('her', 24),\n",
       " ('had', 21),\n",
       " ('Della', 20),\n",
       " ('that', 20),\n",
       " ('for', 20),\n",
       " ('at', 19)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile a frequency distribution of tokens, print out top 20 \n",
    "magifreq = nltk.FreqDist(magitoks)\n",
    "magifreq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has 2466 total tokens.\n",
      "The text has 825 uniq words.\n",
      "Type-token ratio (TTR): 0.33454987834549876\n"
     ]
    }
   ],
   "source": [
    "# print out token and type counts, TTR\n",
    "print(\"The text has\", len(magitoks), \"total tokens.\")\n",
    "print(\"The text has\", len(magifreq), \"uniq words.\")\n",
    "print(\"Type-token ratio (TTR):\", len(magifreq)/len(magitoks))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
