{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emily Yarish, eay18@pitt.edu, Sept 5, 2017\n",
    "- name: Comparative sentence dataset, author: Nitin Jindal and Bing Liu, \n",
    "- size: 279121, url: http://www.nltk.org/nltk_data/, makeup: sentences in one file, words in another, \n",
    "- license: Creative Commons Attribution 4.0 International \n",
    "- notes: seems to be a corpus full of sentences troubleshooting some technical issues people are having with a remote for a certain project. It could also be reviews of the product. There are also key words in another text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpus_root = 'data/comparative_sentences'\n",
    "abc = PlaintextCorpusReader(corpus_root, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['*****************************************************************************', 'dvd', 'player', ':', 'Apex', 'AD2600', 'Progressive', '-', 'scan', 'DVD', 'player', '*****************************************************************************', 'troubleshooting', 'ad', '-', '2500', 'and', 'ad', '-', '2600', 'no', 'picture', 'scrolling', 'b', '/', 'w', '.', 'repost', 'from', 'january', '13', ',', '2004', 'with', 'a', 'better', 'fit', 'title', '.', 'does', 'your', 'apex', 'dvd', 'player', 'only', 'play', 'dvd', 'audio', 'without', 'video']\n",
      "['//', 'This', 'file', 'contains', 'list', 'of', 'keywords', 'used', '.', 'POS']\n",
      "\n",
      "The corpus only contains 4 files, one of which is the actual sentences, and the other is just the common/important words. One is a ReadMe file.\n",
      "\n",
      " ['.DS_Store', 'README.txt', 'labeledSentences.txt', 'listOfkeywords.txt']\n"
     ]
    }
   ],
   "source": [
    "# testing the data inside\n",
    "print(abc.words('labeledSentences.txt')[:50])\n",
    "print(abc.words('listOfkeywords.txt')[:10])\n",
    "\n",
    "print('\\nThe corpus only contains', len(abc.fileids()), 'files, one of which is the actual sentences, and the other is just the common/important words. One is a ReadMe file.')\n",
    "\n",
    "# I was expecting only two files instead there were 3 that did not include the ReadMe, \n",
    "#so I looked to see what was left behind.\n",
    "print('\\n', list(abc.fileids()))\n",
    "\n",
    "# Seems there is a hidden DS_Store file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab_len=len(abc.words('labeledSentences.txt')) # I am still having encoding issues, and I have no idea why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labeled_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c723d3d6c3b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# If I had no encoding issues, labeled_words and key_words would be two lists of all the corresponding words in each file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Then, this for loop would appropriately add to the other lists and allow me to remove duplicates, that way yes_key and no_key would be the lists with no duplicates, and the original lists would still be intact for potential further investigation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# If this word is in key words, then put it in key words, if not, put it in labeled words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labeled_words' is not defined"
     ]
    }
   ],
   "source": [
    "# Time to discover! I want to know how many words weren't in the special list of key words file\n",
    "# This probably won't run but whatever\n",
    "yes_key = [] \n",
    "no_key = []\n",
    "\n",
    "# If I had no encoding issues, labeled_words and key_words would be two lists of all the corresponding words in each file\n",
    "# Then, this for loop would appropriately add to the other lists and allow me to remove duplicates, that way yes_key and no_key would be the lists with no duplicates, and the original lists would still be intact for potential further investigation\n",
    "for word in labeled_words:\n",
    "        if word in key_words:\n",
    "            # If this word is in key words, then put it in key words, if not, put it in labeled words\n",
    "            yes_key.extend(word)\n",
    "        if word not in key_words:\n",
    "            no_key.extend(word)\n",
    "\n",
    "# This would be me removing duplicates and such, if I could, with no encoding issues\n",
    "list(set(yes_key))\n",
    "list(set(no_key))\n",
    "\n",
    "print('Number of words not in key words:', len(no_key))\n",
    "print('Number of words in key words:', len(yes_key)) #This will take into account duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I had more time, I would fix the encoding issue and work to try and remove duplicates from my data, which I plan on re-doing the encoding issue over the weekend when I have more time to fix it. I have no idea why these encoding issues are happening, but it isn't allowing me to finish the homework. I plan on fixing it, like I said, probably after class today or during the day tomorrow. It's frustating to not be able to finish the first homework on time but I have a feeling I will eventually be able to figure it out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
